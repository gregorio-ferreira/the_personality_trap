{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9823bc9b",
   "metadata": {},
   "source": [
    "# Appendix Tables: Accuracy and Error Metrics\n",
    "\n",
    "This notebook replicates the appendix tables from the paper:\n",
    "\n",
    "- **Table A6**: Average accuracy and error metrics by EPQR-A scale for Base population vs input reference\n",
    "- **Table A7**: Average accuracy and error metrics by EPQR-A scale for MaxN/MaxP populations vs input reference\n",
    "\n",
    "## Metrics Explained\n",
    "\n",
    "For each EPQR-A question, we compare the LLM-generated answer with the reference (input) answer:\n",
    "\n",
    "### Binary Classification Metrics\n",
    "\n",
    "- **Accuracy**: Percentage of correct predictions (TP + TN) / Total\n",
    "- **Precision**: Of all positive predictions, how many were correct? TP / (TP + FP)\n",
    "- **Recall (Sensitivity)**: Of all actual positives, how many were identified? TP / (TP + FN)\n",
    "- **Specificity**: Of all actual negatives, how many were identified? TN / (TN + FP)\n",
    "\n",
    "Where:\n",
    "- **TP (True Positive)**: Both reference and LLM answered \"Yes\"\n",
    "- **TN (True Negative)**: Both reference and LLM answered \"No\"\n",
    "- **FP (False Positive)**: Reference=\"No\", LLM=\"Yes\"\n",
    "- **FN (False Negative)**: Reference=\"Yes\", LLM=\"No\"\n",
    "\n",
    "### Error Metrics (Scale-level)\n",
    "\n",
    "For each personality and category, we sum the evaluations (1 for \"Yes\", 0 for \"No\") to get a scale score:\n",
    "\n",
    "- **MAE (Mean Absolute Error)**: Average absolute difference between LLM and reference scale scores\n",
    "- **RMSE (Root Mean Squared Error)**: Square root of average squared differences between LLM and reference scale scores\n",
    "\n",
    "These metrics measure how well the LLM reproduces the **overall trait intensity** rather than individual question accuracy.\n",
    "\n",
    "## EPQR-A Categories\n",
    "\n",
    "- **E (Extraversion)**: Questions 2, 4, 13, 15, 20, 23\n",
    "- **N (Neuroticism)**: Questions 1, 9, 11, 14, 18, 21\n",
    "- **P (Psychoticism)**: Questions 6, 8, 12, 19, 22, 24\n",
    "- **L (Lie scale)**: Questions 3, 5, 7, 10, 16, 17"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23860752",
   "metadata": {},
   "source": [
    "## Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7358c2c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using schema: personality_trap\n",
      "Active schema: test_validation_schema\n"
     ]
    }
   ],
   "source": [
    "# Standard libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Database connection\n",
    "from personas_backend.db.db_handler import DatabaseHandler\n",
    "from personas_backend import ACTIVE_SCHEMA\n",
    "\n",
    "# Evaluations package\n",
    "from evaluations import data_access\n",
    "from evaluations import table_accuracy\n",
    "\n",
    "# Configuration\n",
    "SCHEMA = \"personality_trap\"\n",
    "print(f\"Using schema: {SCHEMA}\")\n",
    "print(f\"Active schema: {ACTIVE_SCHEMA}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f26e39d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Connected to database\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Engine(postgresql://personas:***@localhost:5432/personas)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Connect to database\n",
    "db_handler = DatabaseHandler()\n",
    "conn = db_handler.connection\n",
    "\n",
    "print(f\"✅ Connected to database\")\n",
    "conn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02e14ca",
   "metadata": {},
   "source": [
    "## Load Experiment and Reference Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6605e830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading questionnaire data from personality_trap.experiments_evals...\n",
      "Loaded 297360 questionnaire records\n",
      "Models: ['GPT-3.5' 'GPT-4o' 'Claude-3.5-s' 'Llama3.2-3B' 'Llama3.1-70B']\n",
      "Populations: ['gpt35' 'gpt4o' 'maxN_gpt4o' 'maxP_gpt4o' 'claude35sonnet' 'llama323B'\n",
      " 'llama3170B' 'maxN_claude35sonnet' 'maxP_claude35sonnet' 'maxN_gpt35'\n",
      " 'maxP_gpt35' 'maxN_llama3170B' 'maxP_llama3170B' 'maxN_llama323B'\n",
      " 'maxP_llama323B']\n",
      "Total EPQR-A records: 297360\n",
      "Experiment groups: [np.int64(307), np.int64(308), np.int64(312), np.int64(313), np.int64(343), np.int64(344), np.int64(345), np.int64(356), np.int64(357), np.int64(358), np.int64(359), np.int64(360), np.int64(361), np.int64(362), np.int64(363)]\n",
      "Models: ['Claude-3.5-s', 'GPT-3.5', 'GPT-4o', 'Llama3.1-70B', 'Llama3.2-3B']\n",
      "Populations: ['Base', 'MaxN', 'MaxP']\n",
      "Categories: ['E', 'L', 'N', 'P']\n",
      "Loaded 297360 questionnaire records\n",
      "Models: ['GPT-3.5' 'GPT-4o' 'Claude-3.5-s' 'Llama3.2-3B' 'Llama3.1-70B']\n",
      "Populations: ['gpt35' 'gpt4o' 'maxN_gpt4o' 'maxP_gpt4o' 'claude35sonnet' 'llama323B'\n",
      " 'llama3170B' 'maxN_claude35sonnet' 'maxP_claude35sonnet' 'maxN_gpt35'\n",
      " 'maxP_gpt35' 'maxN_llama3170B' 'maxP_llama3170B' 'maxN_llama323B'\n",
      " 'maxP_llama323B']\n",
      "Total EPQR-A records: 297360\n",
      "Experiment groups: [np.int64(307), np.int64(308), np.int64(312), np.int64(313), np.int64(343), np.int64(344), np.int64(345), np.int64(356), np.int64(357), np.int64(358), np.int64(359), np.int64(360), np.int64(361), np.int64(362), np.int64(363)]\n",
      "Models: ['Claude-3.5-s', 'GPT-3.5', 'GPT-4o', 'Llama3.1-70B', 'Llama3.2-3B']\n",
      "Populations: ['Base', 'MaxN', 'MaxP']\n",
      "Categories: ['E', 'L', 'N', 'P']\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "experiments_group_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "model_provider",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "model",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "questionnaire",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "population",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "personality_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "repeated",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "experiment_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "question_number",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "answer",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "category",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "key",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "eval",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "model_clean",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "population_mapped",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "population_display",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "e272ef62-d81b-4d82-a29a-4b4bec56756f",
       "rows": [
        [
         "0",
         "307",
         "openai",
         "gpt-3.5-turbo-0125",
         "epqra",
         "generated_gpt35_spain826",
         "1",
         "0",
         "96033",
         "1",
         "1",
         "N",
         "1",
         "1",
         "GPT-3.5",
         "gpt35",
         "Base"
        ],
        [
         "1",
         "307",
         "openai",
         "gpt-3.5-turbo-0125",
         "epqra",
         "generated_gpt35_spain826",
         "1",
         "0",
         "96033",
         "2",
         "0",
         "E",
         "1",
         "0",
         "GPT-3.5",
         "gpt35",
         "Base"
        ],
        [
         "2",
         "307",
         "openai",
         "gpt-3.5-turbo-0125",
         "epqra",
         "generated_gpt35_spain826",
         "1",
         "0",
         "96033",
         "3",
         "1",
         "P",
         "0",
         "0",
         "GPT-3.5",
         "gpt35",
         "Base"
        ],
        [
         "3",
         "307",
         "openai",
         "gpt-3.5-turbo-0125",
         "epqra",
         "generated_gpt35_spain826",
         "1",
         "0",
         "96033",
         "4",
         "0",
         "E",
         "1",
         "0",
         "GPT-3.5",
         "gpt35",
         "Base"
        ],
        [
         "4",
         "307",
         "openai",
         "gpt-3.5-turbo-0125",
         "epqra",
         "generated_gpt35_spain826",
         "1",
         "0",
         "96033",
         "5",
         "0",
         "L",
         "0",
         "1",
         "GPT-3.5",
         "gpt35",
         "Base"
        ]
       ],
       "shape": {
        "columns": 16,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiments_group_id</th>\n",
       "      <th>model_provider</th>\n",
       "      <th>model</th>\n",
       "      <th>questionnaire</th>\n",
       "      <th>population</th>\n",
       "      <th>personality_id</th>\n",
       "      <th>repeated</th>\n",
       "      <th>experiment_id</th>\n",
       "      <th>question_number</th>\n",
       "      <th>answer</th>\n",
       "      <th>category</th>\n",
       "      <th>key</th>\n",
       "      <th>eval</th>\n",
       "      <th>model_clean</th>\n",
       "      <th>population_mapped</th>\n",
       "      <th>population_display</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>307</td>\n",
       "      <td>openai</td>\n",
       "      <td>gpt-3.5-turbo-0125</td>\n",
       "      <td>epqra</td>\n",
       "      <td>generated_gpt35_spain826</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96033</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>GPT-3.5</td>\n",
       "      <td>gpt35</td>\n",
       "      <td>Base</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>307</td>\n",
       "      <td>openai</td>\n",
       "      <td>gpt-3.5-turbo-0125</td>\n",
       "      <td>epqra</td>\n",
       "      <td>generated_gpt35_spain826</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96033</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>E</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>GPT-3.5</td>\n",
       "      <td>gpt35</td>\n",
       "      <td>Base</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>307</td>\n",
       "      <td>openai</td>\n",
       "      <td>gpt-3.5-turbo-0125</td>\n",
       "      <td>epqra</td>\n",
       "      <td>generated_gpt35_spain826</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96033</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>P</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>GPT-3.5</td>\n",
       "      <td>gpt35</td>\n",
       "      <td>Base</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>307</td>\n",
       "      <td>openai</td>\n",
       "      <td>gpt-3.5-turbo-0125</td>\n",
       "      <td>epqra</td>\n",
       "      <td>generated_gpt35_spain826</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96033</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>E</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>GPT-3.5</td>\n",
       "      <td>gpt35</td>\n",
       "      <td>Base</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>307</td>\n",
       "      <td>openai</td>\n",
       "      <td>gpt-3.5-turbo-0125</td>\n",
       "      <td>epqra</td>\n",
       "      <td>generated_gpt35_spain826</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96033</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>L</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>GPT-3.5</td>\n",
       "      <td>gpt35</td>\n",
       "      <td>Base</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   experiments_group_id model_provider               model questionnaire  \\\n",
       "0                   307         openai  gpt-3.5-turbo-0125         epqra   \n",
       "1                   307         openai  gpt-3.5-turbo-0125         epqra   \n",
       "2                   307         openai  gpt-3.5-turbo-0125         epqra   \n",
       "3                   307         openai  gpt-3.5-turbo-0125         epqra   \n",
       "4                   307         openai  gpt-3.5-turbo-0125         epqra   \n",
       "\n",
       "                 population  personality_id  repeated  experiment_id  \\\n",
       "0  generated_gpt35_spain826               1         0          96033   \n",
       "1  generated_gpt35_spain826               1         0          96033   \n",
       "2  generated_gpt35_spain826               1         0          96033   \n",
       "3  generated_gpt35_spain826               1         0          96033   \n",
       "4  generated_gpt35_spain826               1         0          96033   \n",
       "\n",
       "   question_number  answer category  key  eval model_clean population_mapped  \\\n",
       "0                1       1        N    1     1     GPT-3.5             gpt35   \n",
       "1                2       0        E    1     0     GPT-3.5             gpt35   \n",
       "2                3       1        P    0     0     GPT-3.5             gpt35   \n",
       "3                4       0        E    1     0     GPT-3.5             gpt35   \n",
       "4                5       0        L    0     1     GPT-3.5             gpt35   \n",
       "\n",
       "  population_display  \n",
       "0               Base  \n",
       "1               Base  \n",
       "2               Base  \n",
       "3               Base  \n",
       "4               Base  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load EPQR-A questionnaire experiment data\n",
    "with conn.connect() as connection:\n",
    "    epqra_data = data_access.load_questionnaire_experiments(\n",
    "        connection, \n",
    "        schema=SCHEMA,\n",
    "        questionnaires=[\"epqra\"]\n",
    "    )\n",
    "\n",
    "print(f\"Total EPQR-A records: {len(epqra_data)}\")\n",
    "print(f\"Experiment groups: {sorted(epqra_data['experiments_group_id'].unique())}\")\n",
    "print(f\"Models: {sorted(epqra_data['model_clean'].unique())}\")\n",
    "print(f\"Populations: {sorted(epqra_data['population_display'].unique())}\")\n",
    "print(f\"Categories: {sorted(epqra_data['category'].unique())}\")\n",
    "\n",
    "epqra_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "72cf4538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading reference questionnaire data...\n",
      "\n",
      "Loaded 19824 reference questionnaire records\n",
      "Unique personalities: 826\n",
      "Questions per personality: 24\n",
      "Categories: ['E', 'L', 'N', 'P']\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "personality_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "question_number",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "question",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "category",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "key",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "answer",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "ref_eval",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "4ac6b7f1-5409-4a8f-a1e6-47e8c9e8a669",
       "rows": [
        [
         "0",
         "1",
         "1",
         "1",
         "Does your mood often go up and down?",
         "N",
         "True",
         "True",
         "1"
        ],
        [
         "1",
         "2",
         "1",
         "2",
         "Are you a talkative person?",
         "E",
         "True",
         "False",
         "0"
        ],
        [
         "2",
         "3",
         "1",
         "3",
         "Would being in debt worry you?",
         "P",
         "False",
         "True",
         "0"
        ],
        [
         "3",
         "4",
         "1",
         "4",
         "Are you rather lively?",
         "E",
         "True",
         "False",
         "0"
        ],
        [
         "4",
         "5",
         "1",
         "5",
         "Were you ever greedy by helping yourself to more than your share of anything?",
         "L",
         "False",
         "False",
         "1"
        ]
       ],
       "shape": {
        "columns": 8,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>personality_id</th>\n",
       "      <th>question_number</th>\n",
       "      <th>question</th>\n",
       "      <th>category</th>\n",
       "      <th>key</th>\n",
       "      <th>answer</th>\n",
       "      <th>ref_eval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Does your mood often go up and down?</td>\n",
       "      <td>N</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Are you a talkative person?</td>\n",
       "      <td>E</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Would being in debt worry you?</td>\n",
       "      <td>P</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>Are you rather lively?</td>\n",
       "      <td>E</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>Were you ever greedy by helping yourself to mo...</td>\n",
       "      <td>L</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  personality_id  question_number  \\\n",
       "0   1               1                1   \n",
       "1   2               1                2   \n",
       "2   3               1                3   \n",
       "3   4               1                4   \n",
       "4   5               1                5   \n",
       "\n",
       "                                            question category    key  answer  \\\n",
       "0               Does your mood often go up and down?        N   True    True   \n",
       "1                        Are you a talkative person?        E   True   False   \n",
       "2                     Would being in debt worry you?        P  False    True   \n",
       "3                             Are you rather lively?        E   True   False   \n",
       "4  Were you ever greedy by helping yourself to mo...        L  False   False   \n",
       "\n",
       "   ref_eval  \n",
       "0         1  \n",
       "1         0  \n",
       "2         0  \n",
       "3         0  \n",
       "4         1  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load reference questionnaire data (input personality profiles)\n",
    "print(\"Loading reference questionnaire data...\")\n",
    "reference_data = data_access.load_reference_questionnaires(conn, schema=SCHEMA)\n",
    "\n",
    "print(f\"\\nLoaded {len(reference_data)} reference questionnaire records\")\n",
    "print(f\"Unique personalities: {reference_data['personality_id'].nunique()}\")\n",
    "print(f\"Questions per personality: {len(reference_data) // reference_data['personality_id'].nunique()}\")\n",
    "print(f\"Categories: {sorted(reference_data['category'].unique())}\")\n",
    "\n",
    "reference_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04194cb",
   "metadata": {},
   "source": [
    "## Helper Functions from table_accuracy Module\n",
    "\n",
    "The following functions are now available from the `evaluations.table_accuracy` module:\n",
    "\n",
    "- `table_accuracy.calculate_accuracy_metrics()` - Binary classification metrics\n",
    "- `table_accuracy.compute_error_metrics()` - MAE and RMSE calculations\n",
    "- `table_accuracy.format_metrics_table()` - Publication formatting\n",
    "- `table_accuracy.prepare_accuracy_data()` - Data preparation\n",
    "- `table_accuracy.create_table_a6()` - Complete Table A6 generator\n",
    "- `table_accuracy.create_table_a7()` - Complete Table A7 generator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0a0b24",
   "metadata": {},
   "source": [
    "## Prepare Data for Accuracy Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8222c795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared 297360 records for accuracy analysis\n",
      "Columns: ['experiments_group_id', 'model_clean', 'population_display', 'personality_id', 'experiment_id', 'question_number', 'answer_exp', 'category', 'key_exp', 'answer_ref', 'key_ref', 'equal', 'tp', 'pred_pos', 'act_pos', 'tn', 'pred_neg', 'act_neg']\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "experiments_group_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "model_clean",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "population_display",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "personality_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "experiment_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "question_number",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "answer_exp",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "category",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "key_exp",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "answer_ref",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "key_ref",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "equal",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "tp",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "pred_pos",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "act_pos",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "tn",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "pred_neg",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "act_neg",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "2035bc96-a1a1-486a-a80b-e90c71ad919f",
       "rows": [
        [
         "0",
         "307",
         "GPT-3.5",
         "Base",
         "1",
         "96033",
         "1",
         "1",
         "N",
         "1",
         "True",
         "True",
         "True",
         "1",
         "1",
         "1",
         "0",
         "0",
         "0"
        ],
        [
         "1",
         "307",
         "GPT-3.5",
         "Base",
         "1",
         "96033",
         "2",
         "0",
         "E",
         "1",
         "False",
         "True",
         "True",
         "0",
         "0",
         "0",
         "1",
         "1",
         "1"
        ],
        [
         "2",
         "307",
         "GPT-3.5",
         "Base",
         "1",
         "96033",
         "3",
         "1",
         "P",
         "0",
         "True",
         "False",
         "True",
         "1",
         "1",
         "1",
         "0",
         "0",
         "0"
        ],
        [
         "3",
         "307",
         "GPT-3.5",
         "Base",
         "1",
         "96033",
         "4",
         "0",
         "E",
         "1",
         "False",
         "True",
         "True",
         "0",
         "0",
         "0",
         "1",
         "1",
         "1"
        ],
        [
         "4",
         "307",
         "GPT-3.5",
         "Base",
         "1",
         "96033",
         "5",
         "0",
         "L",
         "0",
         "False",
         "False",
         "True",
         "0",
         "0",
         "0",
         "1",
         "1",
         "1"
        ]
       ],
       "shape": {
        "columns": 18,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiments_group_id</th>\n",
       "      <th>model_clean</th>\n",
       "      <th>population_display</th>\n",
       "      <th>personality_id</th>\n",
       "      <th>experiment_id</th>\n",
       "      <th>question_number</th>\n",
       "      <th>answer_exp</th>\n",
       "      <th>category</th>\n",
       "      <th>key_exp</th>\n",
       "      <th>answer_ref</th>\n",
       "      <th>key_ref</th>\n",
       "      <th>equal</th>\n",
       "      <th>tp</th>\n",
       "      <th>pred_pos</th>\n",
       "      <th>act_pos</th>\n",
       "      <th>tn</th>\n",
       "      <th>pred_neg</th>\n",
       "      <th>act_neg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>307</td>\n",
       "      <td>GPT-3.5</td>\n",
       "      <td>Base</td>\n",
       "      <td>1</td>\n",
       "      <td>96033</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>307</td>\n",
       "      <td>GPT-3.5</td>\n",
       "      <td>Base</td>\n",
       "      <td>1</td>\n",
       "      <td>96033</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>E</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>307</td>\n",
       "      <td>GPT-3.5</td>\n",
       "      <td>Base</td>\n",
       "      <td>1</td>\n",
       "      <td>96033</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>P</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>307</td>\n",
       "      <td>GPT-3.5</td>\n",
       "      <td>Base</td>\n",
       "      <td>1</td>\n",
       "      <td>96033</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>E</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>307</td>\n",
       "      <td>GPT-3.5</td>\n",
       "      <td>Base</td>\n",
       "      <td>1</td>\n",
       "      <td>96033</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>L</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   experiments_group_id model_clean population_display  personality_id  \\\n",
       "0                   307     GPT-3.5               Base               1   \n",
       "1                   307     GPT-3.5               Base               1   \n",
       "2                   307     GPT-3.5               Base               1   \n",
       "3                   307     GPT-3.5               Base               1   \n",
       "4                   307     GPT-3.5               Base               1   \n",
       "\n",
       "   experiment_id  question_number  answer_exp category  key_exp  answer_ref  \\\n",
       "0          96033                1           1        N        1        True   \n",
       "1          96033                2           0        E        1       False   \n",
       "2          96033                3           1        P        0        True   \n",
       "3          96033                4           0        E        1       False   \n",
       "4          96033                5           0        L        0       False   \n",
       "\n",
       "   key_ref  equal  tp  pred_pos  act_pos  tn  pred_neg  act_neg  \n",
       "0     True   True   1         1        1   0         0        0  \n",
       "1     True   True   0         0        0   1         1        1  \n",
       "2    False   True   1         1        1   0         0        0  \n",
       "3     True   True   0         0        0   1         1        1  \n",
       "4    False   True   0         0        0   1         1        1  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge experiment data with reference data and calculate binary classification components\n",
    "accuracy_data = table_accuracy.prepare_accuracy_data(\n",
    "    experiment_df=epqra_data,\n",
    "    reference_df=reference_data\n",
    ")\n",
    "\n",
    "print(f\"Prepared {len(accuracy_data)} records for accuracy analysis\")\n",
    "print(f\"Columns: {list(accuracy_data.columns)}\")\n",
    "\n",
    "accuracy_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5907360",
   "metadata": {},
   "source": [
    "## Filter Data by Population Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "41c8ba8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base population records: 99120\n",
      "Models: ['Claude-3.5-s', 'GPT-3.5', 'GPT-4o', 'Llama3.1-70B', 'Llama3.2-3B']\n",
      "Categories: ['E', 'L', 'N', 'P']\n"
     ]
    }
   ],
   "source": [
    "# Filter for Base population\n",
    "base_data = accuracy_data[\n",
    "    accuracy_data['population_display'] == 'Base'\n",
    "].copy()\n",
    "\n",
    "print(f\"Base population records: {len(base_data)}\")\n",
    "print(f\"Models: {sorted(base_data['model_clean'].unique())}\")\n",
    "print(f\"Categories: {sorted(base_data['category'].unique())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ce4502d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Borderline populations records: 198240\n",
      "Populations: ['MaxN', 'MaxP']\n",
      "Models: ['Claude-3.5-s', 'GPT-3.5', 'GPT-4o', 'Llama3.1-70B', 'Llama3.2-3B']\n",
      "Categories: ['E', 'L', 'N', 'P']\n"
     ]
    }
   ],
   "source": [
    "# Filter for MaxN and MaxP populations (borderline conditions)\n",
    "borderline_data = accuracy_data[\n",
    "    accuracy_data['population_display'].isin(['MaxN', 'MaxP'])\n",
    "].copy()\n",
    "\n",
    "print(f\"Borderline populations records: {len(borderline_data)}\")\n",
    "print(f\"Populations: {sorted(borderline_data['population_display'].unique())}\")\n",
    "print(f\"Models: {sorted(borderline_data['model_clean'].unique())}\")\n",
    "print(f\"Categories: {sorted(borderline_data['category'].unique())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2078f6a4",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Table A6: Base Population Accuracy Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d5ee9a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TABLE A6: Accuracy and Error Metrics for Base Population vs Reference\n",
      "================================================================================\n",
      "\n",
      "Metrics by Model and EPQR-A Category:\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "model_clean",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "category",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "accuracy",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "precision",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "recall",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "specificity",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "mae",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "rmse",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "a6a9c58e-73d4-4b50-aa25-3cde197cbfe8",
       "rows": [
        [
         "0",
         "GPT-4o",
         "E",
         "97.68",
         "96.74",
         "98.10",
         "97.34",
         "0.12469733656174334",
         "0.44422580040261217"
        ],
        [
         "1",
         "GPT-4o",
         "N",
         "93.04",
         "93.40",
         "93.00",
         "93.08",
         "0.400726392251816",
         "0.8299770993660939"
        ],
        [
         "2",
         "GPT-4o",
         "P",
         "98.20",
         "98.25",
         "98.21",
         "98.20",
         "0.09564164648910412",
         "0.32454102439185895"
        ],
        [
         "3",
         "GPT-4o",
         "L",
         "99.23",
         "97.62",
         "97.86",
         "99.51",
         "0.043583535108958835",
         "0.23080027108556853"
        ],
        [
         "4",
         "GPT-3.5",
         "E",
         "91.40",
         "85.78",
         "96.74",
         "87.12",
         "0.38256658595641646",
         "0.7446337481515316"
        ],
        [
         "5",
         "GPT-3.5",
         "N",
         "81.48",
         "79.57",
         "85.96",
         "76.76",
         "1.0145278450363195",
         "1.6563035362995375"
        ],
        [
         "6",
         "GPT-3.5",
         "P",
         "89.79",
         "87.74",
         "92.84",
         "86.65",
         "0.43341404358353514",
         "0.7181493568815238"
        ],
        [
         "7",
         "GPT-3.5",
         "L",
         "98.26",
         "95.86",
         "93.81",
         "99.17",
         "0.09685230024213075",
         "0.37150306572764147"
        ],
        [
         "8",
         "Claude-3.5-s",
         "E",
         "97.70",
         "96.49",
         "98.41",
         "97.13",
         "0.12106537530266344",
         "0.4317877695883728"
        ],
        [
         "9",
         "Claude-3.5-s",
         "N",
         "94.83",
         "91.84",
         "98.70",
         "90.76",
         "0.3050847457627119",
         "0.719833179490498"
        ],
        [
         "10",
         "Claude-3.5-s",
         "P",
         "95.68",
         "96.82",
         "94.59",
         "96.81",
         "0.07990314769975787",
         "0.291111254869791"
        ],
        [
         "11",
         "Claude-3.5-s",
         "L",
         "98.91",
         "96.90",
         "96.67",
         "99.37",
         "0.05569007263922518",
         "0.24106302110709235"
        ],
        [
         "12",
         "Llama3.1-70B",
         "E",
         "97.38",
         "94.90",
         "99.46",
         "95.71",
         "0.14769975786924938",
         "0.5137338982000373"
        ],
        [
         "13",
         "Llama3.1-70B",
         "N",
         "88.03",
         "83.83",
         "95.00",
         "80.70",
         "0.6138014527845036",
         "1.0986454349641446"
        ],
        [
         "14",
         "Llama3.1-70B",
         "P",
         "96.63",
         "97.76",
         "95.54",
         "97.75",
         "0.10774818401937046",
         "0.3355455245290525"
        ],
        [
         "15",
         "Llama3.1-70B",
         "L",
         "98.57",
         "94.55",
         "97.14",
         "98.86",
         "0.07142857142857142",
         "0.3207889789367208"
        ],
        [
         "16",
         "Llama3.2-3B",
         "E",
         "88.32",
         "81.36",
         "95.70",
         "82.39",
         "0.5411622276029056",
         "0.8614701101055839"
        ],
        [
         "17",
         "Llama3.2-3B",
         "N",
         "75.93",
         "83.74",
         "65.85",
         "86.54",
         "1.2893462469733656",
         "1.9155916906856034"
        ],
        [
         "18",
         "Llama3.2-3B",
         "P",
         "78.63",
         "95.50",
         "60.74",
         "97.05",
         "1.2070217917675545",
         "1.584962629695182"
        ],
        [
         "19",
         "Llama3.2-3B",
         "L",
         "86.74",
         "95.07",
         "22.98",
         "99.76",
         "0.7784503631961259",
         "0.9798206091678828"
        ]
       ],
       "shape": {
        "columns": 8,
        "rows": 20
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_clean</th>\n",
       "      <th>category</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>specificity</th>\n",
       "      <th>mae</th>\n",
       "      <th>rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GPT-4o</td>\n",
       "      <td>E</td>\n",
       "      <td>97.68</td>\n",
       "      <td>96.74</td>\n",
       "      <td>98.10</td>\n",
       "      <td>97.34</td>\n",
       "      <td>0.124697</td>\n",
       "      <td>0.444226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GPT-4o</td>\n",
       "      <td>N</td>\n",
       "      <td>93.04</td>\n",
       "      <td>93.40</td>\n",
       "      <td>93.00</td>\n",
       "      <td>93.08</td>\n",
       "      <td>0.400726</td>\n",
       "      <td>0.829977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GPT-4o</td>\n",
       "      <td>P</td>\n",
       "      <td>98.20</td>\n",
       "      <td>98.25</td>\n",
       "      <td>98.21</td>\n",
       "      <td>98.20</td>\n",
       "      <td>0.095642</td>\n",
       "      <td>0.324541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GPT-4o</td>\n",
       "      <td>L</td>\n",
       "      <td>99.23</td>\n",
       "      <td>97.62</td>\n",
       "      <td>97.86</td>\n",
       "      <td>99.51</td>\n",
       "      <td>0.043584</td>\n",
       "      <td>0.230800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GPT-3.5</td>\n",
       "      <td>E</td>\n",
       "      <td>91.40</td>\n",
       "      <td>85.78</td>\n",
       "      <td>96.74</td>\n",
       "      <td>87.12</td>\n",
       "      <td>0.382567</td>\n",
       "      <td>0.744634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GPT-3.5</td>\n",
       "      <td>N</td>\n",
       "      <td>81.48</td>\n",
       "      <td>79.57</td>\n",
       "      <td>85.96</td>\n",
       "      <td>76.76</td>\n",
       "      <td>1.014528</td>\n",
       "      <td>1.656304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GPT-3.5</td>\n",
       "      <td>P</td>\n",
       "      <td>89.79</td>\n",
       "      <td>87.74</td>\n",
       "      <td>92.84</td>\n",
       "      <td>86.65</td>\n",
       "      <td>0.433414</td>\n",
       "      <td>0.718149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GPT-3.5</td>\n",
       "      <td>L</td>\n",
       "      <td>98.26</td>\n",
       "      <td>95.86</td>\n",
       "      <td>93.81</td>\n",
       "      <td>99.17</td>\n",
       "      <td>0.096852</td>\n",
       "      <td>0.371503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Claude-3.5-s</td>\n",
       "      <td>E</td>\n",
       "      <td>97.70</td>\n",
       "      <td>96.49</td>\n",
       "      <td>98.41</td>\n",
       "      <td>97.13</td>\n",
       "      <td>0.121065</td>\n",
       "      <td>0.431788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Claude-3.5-s</td>\n",
       "      <td>N</td>\n",
       "      <td>94.83</td>\n",
       "      <td>91.84</td>\n",
       "      <td>98.70</td>\n",
       "      <td>90.76</td>\n",
       "      <td>0.305085</td>\n",
       "      <td>0.719833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Claude-3.5-s</td>\n",
       "      <td>P</td>\n",
       "      <td>95.68</td>\n",
       "      <td>96.82</td>\n",
       "      <td>94.59</td>\n",
       "      <td>96.81</td>\n",
       "      <td>0.079903</td>\n",
       "      <td>0.291111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Claude-3.5-s</td>\n",
       "      <td>L</td>\n",
       "      <td>98.91</td>\n",
       "      <td>96.90</td>\n",
       "      <td>96.67</td>\n",
       "      <td>99.37</td>\n",
       "      <td>0.055690</td>\n",
       "      <td>0.241063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Llama3.1-70B</td>\n",
       "      <td>E</td>\n",
       "      <td>97.38</td>\n",
       "      <td>94.90</td>\n",
       "      <td>99.46</td>\n",
       "      <td>95.71</td>\n",
       "      <td>0.147700</td>\n",
       "      <td>0.513734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Llama3.1-70B</td>\n",
       "      <td>N</td>\n",
       "      <td>88.03</td>\n",
       "      <td>83.83</td>\n",
       "      <td>95.00</td>\n",
       "      <td>80.70</td>\n",
       "      <td>0.613801</td>\n",
       "      <td>1.098645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Llama3.1-70B</td>\n",
       "      <td>P</td>\n",
       "      <td>96.63</td>\n",
       "      <td>97.76</td>\n",
       "      <td>95.54</td>\n",
       "      <td>97.75</td>\n",
       "      <td>0.107748</td>\n",
       "      <td>0.335546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Llama3.1-70B</td>\n",
       "      <td>L</td>\n",
       "      <td>98.57</td>\n",
       "      <td>94.55</td>\n",
       "      <td>97.14</td>\n",
       "      <td>98.86</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.320789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Llama3.2-3B</td>\n",
       "      <td>E</td>\n",
       "      <td>88.32</td>\n",
       "      <td>81.36</td>\n",
       "      <td>95.70</td>\n",
       "      <td>82.39</td>\n",
       "      <td>0.541162</td>\n",
       "      <td>0.861470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Llama3.2-3B</td>\n",
       "      <td>N</td>\n",
       "      <td>75.93</td>\n",
       "      <td>83.74</td>\n",
       "      <td>65.85</td>\n",
       "      <td>86.54</td>\n",
       "      <td>1.289346</td>\n",
       "      <td>1.915592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Llama3.2-3B</td>\n",
       "      <td>P</td>\n",
       "      <td>78.63</td>\n",
       "      <td>95.50</td>\n",
       "      <td>60.74</td>\n",
       "      <td>97.05</td>\n",
       "      <td>1.207022</td>\n",
       "      <td>1.584963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Llama3.2-3B</td>\n",
       "      <td>L</td>\n",
       "      <td>86.74</td>\n",
       "      <td>95.07</td>\n",
       "      <td>22.98</td>\n",
       "      <td>99.76</td>\n",
       "      <td>0.778450</td>\n",
       "      <td>0.979821</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     model_clean category accuracy precision recall specificity       mae  \\\n",
       "0         GPT-4o        E    97.68     96.74  98.10       97.34  0.124697   \n",
       "1         GPT-4o        N    93.04     93.40  93.00       93.08  0.400726   \n",
       "2         GPT-4o        P    98.20     98.25  98.21       98.20  0.095642   \n",
       "3         GPT-4o        L    99.23     97.62  97.86       99.51  0.043584   \n",
       "4        GPT-3.5        E    91.40     85.78  96.74       87.12  0.382567   \n",
       "5        GPT-3.5        N    81.48     79.57  85.96       76.76  1.014528   \n",
       "6        GPT-3.5        P    89.79     87.74  92.84       86.65  0.433414   \n",
       "7        GPT-3.5        L    98.26     95.86  93.81       99.17  0.096852   \n",
       "8   Claude-3.5-s        E    97.70     96.49  98.41       97.13  0.121065   \n",
       "9   Claude-3.5-s        N    94.83     91.84  98.70       90.76  0.305085   \n",
       "10  Claude-3.5-s        P    95.68     96.82  94.59       96.81  0.079903   \n",
       "11  Claude-3.5-s        L    98.91     96.90  96.67       99.37  0.055690   \n",
       "12  Llama3.1-70B        E    97.38     94.90  99.46       95.71  0.147700   \n",
       "13  Llama3.1-70B        N    88.03     83.83  95.00       80.70  0.613801   \n",
       "14  Llama3.1-70B        P    96.63     97.76  95.54       97.75  0.107748   \n",
       "15  Llama3.1-70B        L    98.57     94.55  97.14       98.86  0.071429   \n",
       "16   Llama3.2-3B        E    88.32     81.36  95.70       82.39  0.541162   \n",
       "17   Llama3.2-3B        N    75.93     83.74  65.85       86.54  1.289346   \n",
       "18   Llama3.2-3B        P    78.63     95.50  60.74       97.05  1.207022   \n",
       "19   Llama3.2-3B        L    86.74     95.07  22.98       99.76  0.778450   \n",
       "\n",
       "        rmse  \n",
       "0   0.444226  \n",
       "1   0.829977  \n",
       "2   0.324541  \n",
       "3   0.230800  \n",
       "4   0.744634  \n",
       "5   1.656304  \n",
       "6   0.718149  \n",
       "7   0.371503  \n",
       "8   0.431788  \n",
       "9   0.719833  \n",
       "10  0.291111  \n",
       "11  0.241063  \n",
       "12  0.513734  \n",
       "13  1.098645  \n",
       "14  0.335546  \n",
       "15  0.320789  \n",
       "16  0.861470  \n",
       "17  1.915592  \n",
       "18  1.584963  \n",
       "19  0.979821  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculate accuracy metrics for Base population\n",
    "base_metrics = table_accuracy.calculate_accuracy_metrics(\n",
    "    base_data, \n",
    "    group_by=['model_clean', 'category']\n",
    ")\n",
    "\n",
    "# Calculate error metrics (MAE, RMSE)\n",
    "base_errors = table_accuracy.compute_error_metrics(\n",
    "    base_data,\n",
    "    group_by_base=['model_clean']\n",
    ")\n",
    "\n",
    "# Merge metrics with errors\n",
    "TABLE_A6 = pd.merge(\n",
    "    base_metrics,\n",
    "    base_errors,\n",
    "    on=['model_clean', 'category'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Format for display\n",
    "TABLE_A6 = table_accuracy.format_metrics_table(\n",
    "    TABLE_A6,\n",
    "    model_col='model_clean',\n",
    "    population_col=None\n",
    ")\n",
    "\n",
    "# Select key columns for display\n",
    "display_cols = ['model_clean', 'category', 'accuracy', 'precision', 'recall', 'specificity', 'mae', 'rmse']\n",
    "TABLE_A6_display = TABLE_A6[display_cols]\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TABLE A6: Accuracy and Error Metrics for Base Population vs Reference\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nMetrics by Model and EPQR-A Category:\")\n",
    "display(TABLE_A6_display)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cede42b9",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Table A7: MaxN/MaxP Populations Accuracy Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cecc15d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TABLE A7: Accuracy and Error Metrics for MaxN/MaxP Populations vs Reference\n",
      "================================================================================\n",
      "\n",
      "Metrics by Model, Population, and EPQR-A Category:\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "model_clean",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "population_display",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "category",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "accuracy",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "precision",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "recall",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "specificity",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "mae",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "rmse",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "b621b398-1382-4510-b0c6-05e18d3ea43c",
       "rows": [
        [
         "0",
         "GPT-4o",
         "MaxN",
         "E",
         "97.42",
         "96.43",
         "97.83",
         "97.09",
         "0.13559322033898305",
         "0.4589703182414244"
        ],
        [
         "1",
         "GPT-4o",
         "MaxN",
         "N",
         "51.43",
         "51.37",
         "99.57",
         "0.75",
         "2.914043583535109",
         "3.774355933383126"
        ],
        [
         "2",
         "GPT-4o",
         "MaxN",
         "P",
         "97.34",
         "96.71",
         "98.09",
         "96.56",
         "0.13075060532687652",
         "0.36492727060734964"
        ],
        [
         "3",
         "GPT-4o",
         "MaxN",
         "L",
         "98.81",
         "96.21",
         "96.79",
         "99.22",
         "0.06174334140435835",
         "0.30132877638386546"
        ],
        [
         "4",
         "GPT-4o",
         "MaxP",
         "E",
         "97.52",
         "96.35",
         "98.14",
         "97.02",
         "0.13196125907990314",
         "0.45232785041549367"
        ],
        [
         "5",
         "GPT-4o",
         "MaxP",
         "N",
         "86.20",
         "87.40",
         "85.41",
         "87.03",
         "0.7481840193704601",
         "1.2477582804342562"
        ],
        [
         "6",
         "GPT-4o",
         "MaxP",
         "P",
         "35.01",
         "38.30",
         "46.02",
         "23.67",
         "0.8559322033898306",
         "1.139750620529587"
        ],
        [
         "7",
         "GPT-4o",
         "MaxP",
         "L",
         "97.54",
         "90.80",
         "95.12",
         "98.03",
         "0.12106537530266344",
         "0.4846306099362349"
        ],
        [
         "8",
         "GPT-3.5",
         "MaxN",
         "E",
         "86.68",
         "79.88",
         "93.70",
         "81.05",
         "0.5351089588377724",
         "0.9951456023998634"
        ],
        [
         "9",
         "GPT-3.5",
         "MaxN",
         "N",
         "50.50",
         "51.33",
         "67.55",
         "32.56",
         "2.582324455205811",
         "3.188014783005028"
        ],
        [
         "10",
         "GPT-3.5",
         "MaxN",
         "P",
         "89.33",
         "86.99",
         "92.84",
         "85.71",
         "0.3813559322033898",
         "0.6827164088516213"
        ],
        [
         "11",
         "GPT-3.5",
         "MaxN",
         "L",
         "98.26",
         "94.56",
         "95.24",
         "98.88",
         "0.0847457627118644",
         "0.3300891361017462"
        ],
        [
         "12",
         "GPT-3.5",
         "MaxP",
         "E",
         "74.03",
         "65.31",
         "88.90",
         "62.10",
         "0.986682808716707",
         "1.4451220446629913"
        ],
        [
         "13",
         "GPT-3.5",
         "MaxP",
         "N",
         "75.04",
         "80.31",
         "68.02",
         "82.44",
         "1.354721549636804",
         "1.9407070427207347"
        ],
        [
         "14",
         "GPT-3.5",
         "MaxP",
         "P",
         "54.70",
         "54.13",
         "70.09",
         "38.86",
         "1.1222760290556901",
         "1.400881770049198"
        ],
        [
         "15",
         "GPT-3.5",
         "MaxP",
         "L",
         "97.56",
         "93.26",
         "92.26",
         "98.64",
         "0.12953995157384987",
         "0.4655180144653562"
        ],
        [
         "16",
         "Claude-3.5-s",
         "MaxN",
         "E",
         "97.48",
         "96.10",
         "98.32",
         "96.80",
         "0.1271186440677966",
         "0.4414920772078341"
        ],
        [
         "17",
         "Claude-3.5-s",
         "MaxN",
         "N",
         "51.29",
         "51.29",
         "100.00",
         "0.00",
         "2.9225181598062955",
         "3.792435442556197"
        ],
        [
         "18",
         "Claude-3.5-s",
         "MaxN",
         "P",
         "97.58",
         "98.42",
         "96.78",
         "98.40",
         "0.05811138014527845",
         "0.24106302110709235"
        ],
        [
         "19",
         "Claude-3.5-s",
         "MaxN",
         "L",
         "98.26",
         "96.54",
         "93.10",
         "99.32",
         "0.09443099273607748",
         "0.3300891361017462"
        ],
        [
         "20",
         "Claude-3.5-s",
         "MaxP",
         "E",
         "97.74",
         "96.00",
         "99.05",
         "96.69",
         "0.11864406779661017",
         "0.4509876168016973"
        ],
        [
         "21",
         "Claude-3.5-s",
         "MaxP",
         "N",
         "91.51",
         "90.80",
         "92.84",
         "90.10",
         "0.4975786924939467",
         "1.0054331821544582"
        ],
        [
         "22",
         "Claude-3.5-s",
         "MaxP",
         "P",
         "22.32",
         "26.77",
         "30.63",
         "13.76",
         "0.5084745762711864",
         "0.8204410318132612"
        ],
        [
         "23",
         "Claude-3.5-s",
         "MaxP",
         "L",
         "91.77",
         "71.73",
         "84.88",
         "93.17",
         "0.3898305084745763",
         "1.063367577710961"
        ],
        [
         "24",
         "Llama3.1-70B",
         "MaxN",
         "E",
         "97.88",
         "95.58",
         "99.86",
         "96.29",
         "0.12469733656174334",
         "0.47069059561868676"
        ],
        [
         "25",
         "Llama3.1-70B",
         "MaxN",
         "N",
         "51.67",
         "51.51",
         "98.86",
         "1.99",
         "2.87772397094431",
         "3.7249567330961386"
        ],
        [
         "26",
         "Llama3.1-70B",
         "MaxN",
         "P",
         "97.76",
         "98.58",
         "96.98",
         "98.57",
         "0.07384987893462469",
         "0.2805218243679647"
        ],
        [
         "27",
         "Llama3.1-70B",
         "MaxN",
         "L",
         "98.67",
         "95.10",
         "97.14",
         "98.98",
         "0.07021791767554479",
         "0.29931317666279067"
        ],
        [
         "28",
         "Llama3.1-70B",
         "MaxP",
         "E",
         "93.10",
         "86.67",
         "99.86",
         "87.67",
         "0.4092009685230024",
         "1.0814303146406286"
        ],
        [
         "29",
         "Llama3.1-70B",
         "MaxP",
         "N",
         "87.33",
         "88.74",
         "86.23",
         "88.48",
         "0.5835351089588378",
         "0.9841356626102458"
        ],
        [
         "30",
         "Llama3.1-70B",
         "MaxP",
         "P",
         "39.16",
         "40.05",
         "40.10",
         "38.21",
         "0.6162227602905569",
         "0.9522497891923889"
        ],
        [
         "31",
         "Llama3.1-70B",
         "MaxP",
         "L",
         "98.41",
         "94.61",
         "96.07",
         "98.88",
         "0.08353510895883777",
         "0.35653701640614627"
        ],
        [
         "32",
         "Llama3.2-3B",
         "MaxN",
         "E",
         "90.19",
         "83.60",
         "97.01",
         "84.72",
         "0.48426150121065376",
         "0.7934355371256382"
        ],
        [
         "33",
         "Llama3.2-3B",
         "MaxN",
         "N",
         "59.40",
         "58.13",
         "74.51",
         "43.50",
         "2.3099273607748185",
         "2.9854368071995903"
        ],
        [
         "34",
         "Llama3.2-3B",
         "MaxN",
         "P",
         "78.01",
         "98.57",
         "57.48",
         "99.14",
         "1.2929782082324455",
         "1.6282910425130788"
        ],
        [
         "35",
         "Llama3.2-3B",
         "MaxN",
         "L",
         "83.74",
         "72.97",
         "6.43",
         "99.51",
         "0.9297820823244553",
         "1.0530711456366075"
        ],
        [
         "36",
         "Llama3.2-3B",
         "MaxP",
         "E",
         "83.58",
         "75.24",
         "94.06",
         "75.15",
         "0.7651331719128329",
         "1.0870133683418963"
        ],
        [
         "37",
         "Llama3.2-3B",
         "MaxP",
         "N",
         "71.23",
         "74.82",
         "66.17",
         "76.55",
         "1.4285714285714286",
         "2.0567022665118695"
        ],
        [
         "38",
         "Llama3.2-3B",
         "MaxP",
         "P",
         "63.08",
         "76.27",
         "39.50",
         "87.35",
         "1.5278450363196125",
         "1.850986256314556"
        ],
        [
         "39",
         "Llama3.2-3B",
         "MaxP",
         "L",
         "82.97",
         "46.77",
         "3.45",
         "99.20",
         "0.9733656174334141",
         "1.0769430325692793"
        ]
       ],
       "shape": {
        "columns": 9,
        "rows": 40
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_clean</th>\n",
       "      <th>population_display</th>\n",
       "      <th>category</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>specificity</th>\n",
       "      <th>mae</th>\n",
       "      <th>rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GPT-4o</td>\n",
       "      <td>MaxN</td>\n",
       "      <td>E</td>\n",
       "      <td>97.42</td>\n",
       "      <td>96.43</td>\n",
       "      <td>97.83</td>\n",
       "      <td>97.09</td>\n",
       "      <td>0.135593</td>\n",
       "      <td>0.458970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GPT-4o</td>\n",
       "      <td>MaxN</td>\n",
       "      <td>N</td>\n",
       "      <td>51.43</td>\n",
       "      <td>51.37</td>\n",
       "      <td>99.57</td>\n",
       "      <td>0.75</td>\n",
       "      <td>2.914044</td>\n",
       "      <td>3.774356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GPT-4o</td>\n",
       "      <td>MaxN</td>\n",
       "      <td>P</td>\n",
       "      <td>97.34</td>\n",
       "      <td>96.71</td>\n",
       "      <td>98.09</td>\n",
       "      <td>96.56</td>\n",
       "      <td>0.130751</td>\n",
       "      <td>0.364927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GPT-4o</td>\n",
       "      <td>MaxN</td>\n",
       "      <td>L</td>\n",
       "      <td>98.81</td>\n",
       "      <td>96.21</td>\n",
       "      <td>96.79</td>\n",
       "      <td>99.22</td>\n",
       "      <td>0.061743</td>\n",
       "      <td>0.301329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GPT-4o</td>\n",
       "      <td>MaxP</td>\n",
       "      <td>E</td>\n",
       "      <td>97.52</td>\n",
       "      <td>96.35</td>\n",
       "      <td>98.14</td>\n",
       "      <td>97.02</td>\n",
       "      <td>0.131961</td>\n",
       "      <td>0.452328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GPT-4o</td>\n",
       "      <td>MaxP</td>\n",
       "      <td>N</td>\n",
       "      <td>86.20</td>\n",
       "      <td>87.40</td>\n",
       "      <td>85.41</td>\n",
       "      <td>87.03</td>\n",
       "      <td>0.748184</td>\n",
       "      <td>1.247758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GPT-4o</td>\n",
       "      <td>MaxP</td>\n",
       "      <td>P</td>\n",
       "      <td>35.01</td>\n",
       "      <td>38.30</td>\n",
       "      <td>46.02</td>\n",
       "      <td>23.67</td>\n",
       "      <td>0.855932</td>\n",
       "      <td>1.139751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GPT-4o</td>\n",
       "      <td>MaxP</td>\n",
       "      <td>L</td>\n",
       "      <td>97.54</td>\n",
       "      <td>90.80</td>\n",
       "      <td>95.12</td>\n",
       "      <td>98.03</td>\n",
       "      <td>0.121065</td>\n",
       "      <td>0.484631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GPT-3.5</td>\n",
       "      <td>MaxN</td>\n",
       "      <td>E</td>\n",
       "      <td>86.68</td>\n",
       "      <td>79.88</td>\n",
       "      <td>93.70</td>\n",
       "      <td>81.05</td>\n",
       "      <td>0.535109</td>\n",
       "      <td>0.995146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GPT-3.5</td>\n",
       "      <td>MaxN</td>\n",
       "      <td>N</td>\n",
       "      <td>50.50</td>\n",
       "      <td>51.33</td>\n",
       "      <td>67.55</td>\n",
       "      <td>32.56</td>\n",
       "      <td>2.582324</td>\n",
       "      <td>3.188015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>GPT-3.5</td>\n",
       "      <td>MaxN</td>\n",
       "      <td>P</td>\n",
       "      <td>89.33</td>\n",
       "      <td>86.99</td>\n",
       "      <td>92.84</td>\n",
       "      <td>85.71</td>\n",
       "      <td>0.381356</td>\n",
       "      <td>0.682716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>GPT-3.5</td>\n",
       "      <td>MaxN</td>\n",
       "      <td>L</td>\n",
       "      <td>98.26</td>\n",
       "      <td>94.56</td>\n",
       "      <td>95.24</td>\n",
       "      <td>98.88</td>\n",
       "      <td>0.084746</td>\n",
       "      <td>0.330089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>GPT-3.5</td>\n",
       "      <td>MaxP</td>\n",
       "      <td>E</td>\n",
       "      <td>74.03</td>\n",
       "      <td>65.31</td>\n",
       "      <td>88.90</td>\n",
       "      <td>62.10</td>\n",
       "      <td>0.986683</td>\n",
       "      <td>1.445122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>GPT-3.5</td>\n",
       "      <td>MaxP</td>\n",
       "      <td>N</td>\n",
       "      <td>75.04</td>\n",
       "      <td>80.31</td>\n",
       "      <td>68.02</td>\n",
       "      <td>82.44</td>\n",
       "      <td>1.354722</td>\n",
       "      <td>1.940707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>GPT-3.5</td>\n",
       "      <td>MaxP</td>\n",
       "      <td>P</td>\n",
       "      <td>54.70</td>\n",
       "      <td>54.13</td>\n",
       "      <td>70.09</td>\n",
       "      <td>38.86</td>\n",
       "      <td>1.122276</td>\n",
       "      <td>1.400882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>GPT-3.5</td>\n",
       "      <td>MaxP</td>\n",
       "      <td>L</td>\n",
       "      <td>97.56</td>\n",
       "      <td>93.26</td>\n",
       "      <td>92.26</td>\n",
       "      <td>98.64</td>\n",
       "      <td>0.129540</td>\n",
       "      <td>0.465518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Claude-3.5-s</td>\n",
       "      <td>MaxN</td>\n",
       "      <td>E</td>\n",
       "      <td>97.48</td>\n",
       "      <td>96.10</td>\n",
       "      <td>98.32</td>\n",
       "      <td>96.80</td>\n",
       "      <td>0.127119</td>\n",
       "      <td>0.441492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Claude-3.5-s</td>\n",
       "      <td>MaxN</td>\n",
       "      <td>N</td>\n",
       "      <td>51.29</td>\n",
       "      <td>51.29</td>\n",
       "      <td>100.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.922518</td>\n",
       "      <td>3.792435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Claude-3.5-s</td>\n",
       "      <td>MaxN</td>\n",
       "      <td>P</td>\n",
       "      <td>97.58</td>\n",
       "      <td>98.42</td>\n",
       "      <td>96.78</td>\n",
       "      <td>98.40</td>\n",
       "      <td>0.058111</td>\n",
       "      <td>0.241063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Claude-3.5-s</td>\n",
       "      <td>MaxN</td>\n",
       "      <td>L</td>\n",
       "      <td>98.26</td>\n",
       "      <td>96.54</td>\n",
       "      <td>93.10</td>\n",
       "      <td>99.32</td>\n",
       "      <td>0.094431</td>\n",
       "      <td>0.330089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Claude-3.5-s</td>\n",
       "      <td>MaxP</td>\n",
       "      <td>E</td>\n",
       "      <td>97.74</td>\n",
       "      <td>96.00</td>\n",
       "      <td>99.05</td>\n",
       "      <td>96.69</td>\n",
       "      <td>0.118644</td>\n",
       "      <td>0.450988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Claude-3.5-s</td>\n",
       "      <td>MaxP</td>\n",
       "      <td>N</td>\n",
       "      <td>91.51</td>\n",
       "      <td>90.80</td>\n",
       "      <td>92.84</td>\n",
       "      <td>90.10</td>\n",
       "      <td>0.497579</td>\n",
       "      <td>1.005433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Claude-3.5-s</td>\n",
       "      <td>MaxP</td>\n",
       "      <td>P</td>\n",
       "      <td>22.32</td>\n",
       "      <td>26.77</td>\n",
       "      <td>30.63</td>\n",
       "      <td>13.76</td>\n",
       "      <td>0.508475</td>\n",
       "      <td>0.820441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Claude-3.5-s</td>\n",
       "      <td>MaxP</td>\n",
       "      <td>L</td>\n",
       "      <td>91.77</td>\n",
       "      <td>71.73</td>\n",
       "      <td>84.88</td>\n",
       "      <td>93.17</td>\n",
       "      <td>0.389831</td>\n",
       "      <td>1.063368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Llama3.1-70B</td>\n",
       "      <td>MaxN</td>\n",
       "      <td>E</td>\n",
       "      <td>97.88</td>\n",
       "      <td>95.58</td>\n",
       "      <td>99.86</td>\n",
       "      <td>96.29</td>\n",
       "      <td>0.124697</td>\n",
       "      <td>0.470691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Llama3.1-70B</td>\n",
       "      <td>MaxN</td>\n",
       "      <td>N</td>\n",
       "      <td>51.67</td>\n",
       "      <td>51.51</td>\n",
       "      <td>98.86</td>\n",
       "      <td>1.99</td>\n",
       "      <td>2.877724</td>\n",
       "      <td>3.724957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Llama3.1-70B</td>\n",
       "      <td>MaxN</td>\n",
       "      <td>P</td>\n",
       "      <td>97.76</td>\n",
       "      <td>98.58</td>\n",
       "      <td>96.98</td>\n",
       "      <td>98.57</td>\n",
       "      <td>0.073850</td>\n",
       "      <td>0.280522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Llama3.1-70B</td>\n",
       "      <td>MaxN</td>\n",
       "      <td>L</td>\n",
       "      <td>98.67</td>\n",
       "      <td>95.10</td>\n",
       "      <td>97.14</td>\n",
       "      <td>98.98</td>\n",
       "      <td>0.070218</td>\n",
       "      <td>0.299313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Llama3.1-70B</td>\n",
       "      <td>MaxP</td>\n",
       "      <td>E</td>\n",
       "      <td>93.10</td>\n",
       "      <td>86.67</td>\n",
       "      <td>99.86</td>\n",
       "      <td>87.67</td>\n",
       "      <td>0.409201</td>\n",
       "      <td>1.081430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Llama3.1-70B</td>\n",
       "      <td>MaxP</td>\n",
       "      <td>N</td>\n",
       "      <td>87.33</td>\n",
       "      <td>88.74</td>\n",
       "      <td>86.23</td>\n",
       "      <td>88.48</td>\n",
       "      <td>0.583535</td>\n",
       "      <td>0.984136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Llama3.1-70B</td>\n",
       "      <td>MaxP</td>\n",
       "      <td>P</td>\n",
       "      <td>39.16</td>\n",
       "      <td>40.05</td>\n",
       "      <td>40.10</td>\n",
       "      <td>38.21</td>\n",
       "      <td>0.616223</td>\n",
       "      <td>0.952250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Llama3.1-70B</td>\n",
       "      <td>MaxP</td>\n",
       "      <td>L</td>\n",
       "      <td>98.41</td>\n",
       "      <td>94.61</td>\n",
       "      <td>96.07</td>\n",
       "      <td>98.88</td>\n",
       "      <td>0.083535</td>\n",
       "      <td>0.356537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Llama3.2-3B</td>\n",
       "      <td>MaxN</td>\n",
       "      <td>E</td>\n",
       "      <td>90.19</td>\n",
       "      <td>83.60</td>\n",
       "      <td>97.01</td>\n",
       "      <td>84.72</td>\n",
       "      <td>0.484262</td>\n",
       "      <td>0.793436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Llama3.2-3B</td>\n",
       "      <td>MaxN</td>\n",
       "      <td>N</td>\n",
       "      <td>59.40</td>\n",
       "      <td>58.13</td>\n",
       "      <td>74.51</td>\n",
       "      <td>43.50</td>\n",
       "      <td>2.309927</td>\n",
       "      <td>2.985437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Llama3.2-3B</td>\n",
       "      <td>MaxN</td>\n",
       "      <td>P</td>\n",
       "      <td>78.01</td>\n",
       "      <td>98.57</td>\n",
       "      <td>57.48</td>\n",
       "      <td>99.14</td>\n",
       "      <td>1.292978</td>\n",
       "      <td>1.628291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Llama3.2-3B</td>\n",
       "      <td>MaxN</td>\n",
       "      <td>L</td>\n",
       "      <td>83.74</td>\n",
       "      <td>72.97</td>\n",
       "      <td>6.43</td>\n",
       "      <td>99.51</td>\n",
       "      <td>0.929782</td>\n",
       "      <td>1.053071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Llama3.2-3B</td>\n",
       "      <td>MaxP</td>\n",
       "      <td>E</td>\n",
       "      <td>83.58</td>\n",
       "      <td>75.24</td>\n",
       "      <td>94.06</td>\n",
       "      <td>75.15</td>\n",
       "      <td>0.765133</td>\n",
       "      <td>1.087013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Llama3.2-3B</td>\n",
       "      <td>MaxP</td>\n",
       "      <td>N</td>\n",
       "      <td>71.23</td>\n",
       "      <td>74.82</td>\n",
       "      <td>66.17</td>\n",
       "      <td>76.55</td>\n",
       "      <td>1.428571</td>\n",
       "      <td>2.056702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Llama3.2-3B</td>\n",
       "      <td>MaxP</td>\n",
       "      <td>P</td>\n",
       "      <td>63.08</td>\n",
       "      <td>76.27</td>\n",
       "      <td>39.50</td>\n",
       "      <td>87.35</td>\n",
       "      <td>1.527845</td>\n",
       "      <td>1.850986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Llama3.2-3B</td>\n",
       "      <td>MaxP</td>\n",
       "      <td>L</td>\n",
       "      <td>82.97</td>\n",
       "      <td>46.77</td>\n",
       "      <td>3.45</td>\n",
       "      <td>99.20</td>\n",
       "      <td>0.973366</td>\n",
       "      <td>1.076943</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     model_clean population_display category accuracy precision  recall  \\\n",
       "0         GPT-4o               MaxN        E    97.42     96.43   97.83   \n",
       "1         GPT-4o               MaxN        N    51.43     51.37   99.57   \n",
       "2         GPT-4o               MaxN        P    97.34     96.71   98.09   \n",
       "3         GPT-4o               MaxN        L    98.81     96.21   96.79   \n",
       "4         GPT-4o               MaxP        E    97.52     96.35   98.14   \n",
       "5         GPT-4o               MaxP        N    86.20     87.40   85.41   \n",
       "6         GPT-4o               MaxP        P    35.01     38.30   46.02   \n",
       "7         GPT-4o               MaxP        L    97.54     90.80   95.12   \n",
       "8        GPT-3.5               MaxN        E    86.68     79.88   93.70   \n",
       "9        GPT-3.5               MaxN        N    50.50     51.33   67.55   \n",
       "10       GPT-3.5               MaxN        P    89.33     86.99   92.84   \n",
       "11       GPT-3.5               MaxN        L    98.26     94.56   95.24   \n",
       "12       GPT-3.5               MaxP        E    74.03     65.31   88.90   \n",
       "13       GPT-3.5               MaxP        N    75.04     80.31   68.02   \n",
       "14       GPT-3.5               MaxP        P    54.70     54.13   70.09   \n",
       "15       GPT-3.5               MaxP        L    97.56     93.26   92.26   \n",
       "16  Claude-3.5-s               MaxN        E    97.48     96.10   98.32   \n",
       "17  Claude-3.5-s               MaxN        N    51.29     51.29  100.00   \n",
       "18  Claude-3.5-s               MaxN        P    97.58     98.42   96.78   \n",
       "19  Claude-3.5-s               MaxN        L    98.26     96.54   93.10   \n",
       "20  Claude-3.5-s               MaxP        E    97.74     96.00   99.05   \n",
       "21  Claude-3.5-s               MaxP        N    91.51     90.80   92.84   \n",
       "22  Claude-3.5-s               MaxP        P    22.32     26.77   30.63   \n",
       "23  Claude-3.5-s               MaxP        L    91.77     71.73   84.88   \n",
       "24  Llama3.1-70B               MaxN        E    97.88     95.58   99.86   \n",
       "25  Llama3.1-70B               MaxN        N    51.67     51.51   98.86   \n",
       "26  Llama3.1-70B               MaxN        P    97.76     98.58   96.98   \n",
       "27  Llama3.1-70B               MaxN        L    98.67     95.10   97.14   \n",
       "28  Llama3.1-70B               MaxP        E    93.10     86.67   99.86   \n",
       "29  Llama3.1-70B               MaxP        N    87.33     88.74   86.23   \n",
       "30  Llama3.1-70B               MaxP        P    39.16     40.05   40.10   \n",
       "31  Llama3.1-70B               MaxP        L    98.41     94.61   96.07   \n",
       "32   Llama3.2-3B               MaxN        E    90.19     83.60   97.01   \n",
       "33   Llama3.2-3B               MaxN        N    59.40     58.13   74.51   \n",
       "34   Llama3.2-3B               MaxN        P    78.01     98.57   57.48   \n",
       "35   Llama3.2-3B               MaxN        L    83.74     72.97    6.43   \n",
       "36   Llama3.2-3B               MaxP        E    83.58     75.24   94.06   \n",
       "37   Llama3.2-3B               MaxP        N    71.23     74.82   66.17   \n",
       "38   Llama3.2-3B               MaxP        P    63.08     76.27   39.50   \n",
       "39   Llama3.2-3B               MaxP        L    82.97     46.77    3.45   \n",
       "\n",
       "   specificity       mae      rmse  \n",
       "0        97.09  0.135593  0.458970  \n",
       "1         0.75  2.914044  3.774356  \n",
       "2        96.56  0.130751  0.364927  \n",
       "3        99.22  0.061743  0.301329  \n",
       "4        97.02  0.131961  0.452328  \n",
       "5        87.03  0.748184  1.247758  \n",
       "6        23.67  0.855932  1.139751  \n",
       "7        98.03  0.121065  0.484631  \n",
       "8        81.05  0.535109  0.995146  \n",
       "9        32.56  2.582324  3.188015  \n",
       "10       85.71  0.381356  0.682716  \n",
       "11       98.88  0.084746  0.330089  \n",
       "12       62.10  0.986683  1.445122  \n",
       "13       82.44  1.354722  1.940707  \n",
       "14       38.86  1.122276  1.400882  \n",
       "15       98.64  0.129540  0.465518  \n",
       "16       96.80  0.127119  0.441492  \n",
       "17        0.00  2.922518  3.792435  \n",
       "18       98.40  0.058111  0.241063  \n",
       "19       99.32  0.094431  0.330089  \n",
       "20       96.69  0.118644  0.450988  \n",
       "21       90.10  0.497579  1.005433  \n",
       "22       13.76  0.508475  0.820441  \n",
       "23       93.17  0.389831  1.063368  \n",
       "24       96.29  0.124697  0.470691  \n",
       "25        1.99  2.877724  3.724957  \n",
       "26       98.57  0.073850  0.280522  \n",
       "27       98.98  0.070218  0.299313  \n",
       "28       87.67  0.409201  1.081430  \n",
       "29       88.48  0.583535  0.984136  \n",
       "30       38.21  0.616223  0.952250  \n",
       "31       98.88  0.083535  0.356537  \n",
       "32       84.72  0.484262  0.793436  \n",
       "33       43.50  2.309927  2.985437  \n",
       "34       99.14  1.292978  1.628291  \n",
       "35       99.51  0.929782  1.053071  \n",
       "36       75.15  0.765133  1.087013  \n",
       "37       76.55  1.428571  2.056702  \n",
       "38       87.35  1.527845  1.850986  \n",
       "39       99.20  0.973366  1.076943  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculate accuracy metrics for MaxN/MaxP populations\n",
    "borderline_metrics = table_accuracy.calculate_accuracy_metrics(\n",
    "    borderline_data,\n",
    "    group_by=['model_clean', 'population_display', 'category']\n",
    ")\n",
    "\n",
    "# Calculate error metrics (MAE, RMSE)\n",
    "borderline_errors = table_accuracy.compute_error_metrics(\n",
    "    borderline_data,\n",
    "    group_by_base=['model_clean', 'population_display']\n",
    ")\n",
    "\n",
    "# Merge metrics with errors\n",
    "TABLE_A7 = pd.merge(\n",
    "    borderline_metrics,\n",
    "    borderline_errors,\n",
    "    on=['model_clean', 'population_display', 'category'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Format for display\n",
    "TABLE_A7 = table_accuracy.format_metrics_table(\n",
    "    TABLE_A7,\n",
    "    model_col='model_clean',\n",
    "    population_col='population_display'\n",
    ")\n",
    "\n",
    "# Select key columns for display\n",
    "display_cols = ['model_clean', 'population_display', 'category', 'accuracy', 'precision', 'recall', 'specificity', 'mae', 'rmse']\n",
    "TABLE_A7_display = TABLE_A7[display_cols]\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TABLE A7: Accuracy and Error Metrics for MaxN/MaxP Populations vs Reference\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nMetrics by Model, Population, and EPQR-A Category:\")\n",
    "display(TABLE_A7_display)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2e5113",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "### Table A6 Interpretation\n",
    "\n",
    "Shows how well each model reproduces the reference personality profiles for the **Base population** across the four EPQR-A scales (E, N, P, L).\n",
    "\n",
    "- **Accuracy**: Overall correctness of binary Yes/No predictions\n",
    "- **Precision/Recall/Specificity**: Detailed binary classification performance\n",
    "- **MAE/RMSE**: Scale-level error in reproducing trait intensity\n",
    "\n",
    "### Table A7 Interpretation\n",
    "\n",
    "Compares **MaxN** (maximally neurotic) and **MaxP** (maximally psychotic) borderline populations against the reference, showing:\n",
    "\n",
    "- Whether extreme personality conditions affect model accuracy\n",
    "- Differences in error patterns between borderline populations\n",
    "- Model-specific robustness to personality extremes\n",
    "\n",
    "**Note**: All metrics are formatted using `custom_format()` from the paper's original implementation, ensuring exact replication of published results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b741b0",
   "metadata": {},
   "source": [
    "# Appendix Tables: Accuracy and Error Metrics\n",
    "\n",
    "This notebook replicates the appendix tables from the paper:\n",
    "\n",
    "- **Table A6**: Average accuracy and error metrics by EPQR-A scale for Base population vs input reference\n",
    "- **Table A7**: Average accuracy and error metrics by EPQR-A scale for MaxN/MaxP populations vs input reference\n",
    "\n",
    "## Metrics Explained\n",
    "\n",
    "For each EPQR-A question, we compare the LLM-generated answer with the reference (input) answer:\n",
    "\n",
    "### Binary Classification Metrics\n",
    "\n",
    "- **Accuracy**: Percentage of correct predictions (TP + TN) / Total\n",
    "- **Precision**: Of all positive predictions, how many were correct? TP / (TP + FP)\n",
    "- **Recall (Sensitivity)**: Of all actual positives, how many were identified? TP / (TP + FN)\n",
    "- **Specificity**: Of all actual negatives, how many were identified? TN / (TN + FP)\n",
    "\n",
    "Where:\n",
    "- **TP (True Positive)**: Both reference and LLM answered \"Yes\"\n",
    "- **TN (True Negative)**: Both reference and LLM answered \"No\"\n",
    "- **FP (False Positive)**: Reference=\"No\", LLM=\"Yes\"\n",
    "- **FN (False Negative)**: Reference=\"Yes\", LLM=\"No\"\n",
    "\n",
    "### Error Metrics (Scale-level)\n",
    "\n",
    "For each personality and category, we sum the evaluations (1 for \"Yes\", 0 for \"No\") to get a scale score:\n",
    "\n",
    "- **MAE (Mean Absolute Error)**: Average absolute difference between LLM and reference scale scores\n",
    "- **RMSE (Root Mean Squared Error)**: Square root of average squared differences between LLM and reference scale scores\n",
    "\n",
    "These metrics measure how well the LLM reproduces the **overall trait intensity** rather than individual question accuracy.\n",
    "\n",
    "## EPQR-A Categories\n",
    "\n",
    "- **E (Extraversion)**: Questions 2, 4, 13, 15, 20, 23\n",
    "- **N (Neuroticism)**: Questions 1, 9, 11, 14, 18, 21\n",
    "- **P (Psychoticism)**: Questions 6, 8, 12, 19, 22, 24\n",
    "- **L (Lie scale)**: Questions 3, 5, 7, 10, 16, 17"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c6ab07",
   "metadata": {},
   "source": [
    "## Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5dad5c84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using schema: personality_trap\n",
      "Active schema: test_validation_schema\n"
     ]
    }
   ],
   "source": [
    "# Standard libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Database connection\n",
    "from personas_backend.db.db_handler import DatabaseHandler\n",
    "from personas_backend import ACTIVE_SCHEMA\n",
    "\n",
    "# Evaluations package\n",
    "from evaluations import data_access\n",
    "from evaluations import table_accuracy\n",
    "\n",
    "# Configuration\n",
    "SCHEMA = \"personality_trap\"\n",
    "print(f\"Using schema: {SCHEMA}\")\n",
    "print(f\"Active schema: {ACTIVE_SCHEMA}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3d99531a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Connected to database\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Engine(postgresql://personas:***@localhost:5432/personas)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Connect to database\n",
    "db_handler = DatabaseHandler()\n",
    "conn = db_handler.connection\n",
    "\n",
    "print(f\"✅ Connected to database\")\n",
    "conn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd249de1",
   "metadata": {},
   "source": [
    "## Load Experiment and Reference Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "737a56bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading questionnaire data from personality_trap.experiments_evals...\n",
      "Loaded 297360 questionnaire records\n",
      "Models: ['GPT-3.5' 'GPT-4o' 'Claude-3.5-s' 'Llama3.2-3B' 'Llama3.1-70B']\n",
      "Populations: ['gpt35' 'gpt4o' 'maxN_gpt4o' 'maxP_gpt4o' 'claude35sonnet' 'llama323B'\n",
      " 'llama3170B' 'maxN_claude35sonnet' 'maxP_claude35sonnet' 'maxN_gpt35'\n",
      " 'maxP_gpt35' 'maxN_llama3170B' 'maxP_llama3170B' 'maxN_llama323B'\n",
      " 'maxP_llama323B']\n",
      "Total EPQR-A records: 297360\n",
      "Experiment groups: [np.int64(307), np.int64(308), np.int64(312), np.int64(313), np.int64(343), np.int64(344), np.int64(345), np.int64(356), np.int64(357), np.int64(358), np.int64(359), np.int64(360), np.int64(361), np.int64(362), np.int64(363)]\n",
      "Models: ['Claude-3.5-s', 'GPT-3.5', 'GPT-4o', 'Llama3.1-70B', 'Llama3.2-3B']\n",
      "Populations: ['Base', 'MaxN', 'MaxP']\n",
      "Categories: ['E', 'L', 'N', 'P']\n",
      "Loaded 297360 questionnaire records\n",
      "Models: ['GPT-3.5' 'GPT-4o' 'Claude-3.5-s' 'Llama3.2-3B' 'Llama3.1-70B']\n",
      "Populations: ['gpt35' 'gpt4o' 'maxN_gpt4o' 'maxP_gpt4o' 'claude35sonnet' 'llama323B'\n",
      " 'llama3170B' 'maxN_claude35sonnet' 'maxP_claude35sonnet' 'maxN_gpt35'\n",
      " 'maxP_gpt35' 'maxN_llama3170B' 'maxP_llama3170B' 'maxN_llama323B'\n",
      " 'maxP_llama323B']\n",
      "Total EPQR-A records: 297360\n",
      "Experiment groups: [np.int64(307), np.int64(308), np.int64(312), np.int64(313), np.int64(343), np.int64(344), np.int64(345), np.int64(356), np.int64(357), np.int64(358), np.int64(359), np.int64(360), np.int64(361), np.int64(362), np.int64(363)]\n",
      "Models: ['Claude-3.5-s', 'GPT-3.5', 'GPT-4o', 'Llama3.1-70B', 'Llama3.2-3B']\n",
      "Populations: ['Base', 'MaxN', 'MaxP']\n",
      "Categories: ['E', 'L', 'N', 'P']\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "experiments_group_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "model_provider",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "model",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "questionnaire",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "population",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "personality_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "repeated",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "experiment_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "question_number",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "answer",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "category",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "key",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "eval",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "model_clean",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "population_mapped",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "population_display",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "d89c5ec3-7f04-43f3-bebc-5fc547391047",
       "rows": [
        [
         "0",
         "307",
         "openai",
         "gpt-3.5-turbo-0125",
         "epqra",
         "generated_gpt35_spain826",
         "1",
         "0",
         "96033",
         "1",
         "1",
         "N",
         "1",
         "1",
         "GPT-3.5",
         "gpt35",
         "Base"
        ],
        [
         "1",
         "307",
         "openai",
         "gpt-3.5-turbo-0125",
         "epqra",
         "generated_gpt35_spain826",
         "1",
         "0",
         "96033",
         "2",
         "0",
         "E",
         "1",
         "0",
         "GPT-3.5",
         "gpt35",
         "Base"
        ],
        [
         "2",
         "307",
         "openai",
         "gpt-3.5-turbo-0125",
         "epqra",
         "generated_gpt35_spain826",
         "1",
         "0",
         "96033",
         "3",
         "1",
         "P",
         "0",
         "0",
         "GPT-3.5",
         "gpt35",
         "Base"
        ],
        [
         "3",
         "307",
         "openai",
         "gpt-3.5-turbo-0125",
         "epqra",
         "generated_gpt35_spain826",
         "1",
         "0",
         "96033",
         "4",
         "0",
         "E",
         "1",
         "0",
         "GPT-3.5",
         "gpt35",
         "Base"
        ],
        [
         "4",
         "307",
         "openai",
         "gpt-3.5-turbo-0125",
         "epqra",
         "generated_gpt35_spain826",
         "1",
         "0",
         "96033",
         "5",
         "0",
         "L",
         "0",
         "1",
         "GPT-3.5",
         "gpt35",
         "Base"
        ]
       ],
       "shape": {
        "columns": 16,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiments_group_id</th>\n",
       "      <th>model_provider</th>\n",
       "      <th>model</th>\n",
       "      <th>questionnaire</th>\n",
       "      <th>population</th>\n",
       "      <th>personality_id</th>\n",
       "      <th>repeated</th>\n",
       "      <th>experiment_id</th>\n",
       "      <th>question_number</th>\n",
       "      <th>answer</th>\n",
       "      <th>category</th>\n",
       "      <th>key</th>\n",
       "      <th>eval</th>\n",
       "      <th>model_clean</th>\n",
       "      <th>population_mapped</th>\n",
       "      <th>population_display</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>307</td>\n",
       "      <td>openai</td>\n",
       "      <td>gpt-3.5-turbo-0125</td>\n",
       "      <td>epqra</td>\n",
       "      <td>generated_gpt35_spain826</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96033</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>GPT-3.5</td>\n",
       "      <td>gpt35</td>\n",
       "      <td>Base</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>307</td>\n",
       "      <td>openai</td>\n",
       "      <td>gpt-3.5-turbo-0125</td>\n",
       "      <td>epqra</td>\n",
       "      <td>generated_gpt35_spain826</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96033</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>E</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>GPT-3.5</td>\n",
       "      <td>gpt35</td>\n",
       "      <td>Base</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>307</td>\n",
       "      <td>openai</td>\n",
       "      <td>gpt-3.5-turbo-0125</td>\n",
       "      <td>epqra</td>\n",
       "      <td>generated_gpt35_spain826</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96033</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>P</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>GPT-3.5</td>\n",
       "      <td>gpt35</td>\n",
       "      <td>Base</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>307</td>\n",
       "      <td>openai</td>\n",
       "      <td>gpt-3.5-turbo-0125</td>\n",
       "      <td>epqra</td>\n",
       "      <td>generated_gpt35_spain826</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96033</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>E</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>GPT-3.5</td>\n",
       "      <td>gpt35</td>\n",
       "      <td>Base</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>307</td>\n",
       "      <td>openai</td>\n",
       "      <td>gpt-3.5-turbo-0125</td>\n",
       "      <td>epqra</td>\n",
       "      <td>generated_gpt35_spain826</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96033</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>L</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>GPT-3.5</td>\n",
       "      <td>gpt35</td>\n",
       "      <td>Base</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   experiments_group_id model_provider               model questionnaire  \\\n",
       "0                   307         openai  gpt-3.5-turbo-0125         epqra   \n",
       "1                   307         openai  gpt-3.5-turbo-0125         epqra   \n",
       "2                   307         openai  gpt-3.5-turbo-0125         epqra   \n",
       "3                   307         openai  gpt-3.5-turbo-0125         epqra   \n",
       "4                   307         openai  gpt-3.5-turbo-0125         epqra   \n",
       "\n",
       "                 population  personality_id  repeated  experiment_id  \\\n",
       "0  generated_gpt35_spain826               1         0          96033   \n",
       "1  generated_gpt35_spain826               1         0          96033   \n",
       "2  generated_gpt35_spain826               1         0          96033   \n",
       "3  generated_gpt35_spain826               1         0          96033   \n",
       "4  generated_gpt35_spain826               1         0          96033   \n",
       "\n",
       "   question_number  answer category  key  eval model_clean population_mapped  \\\n",
       "0                1       1        N    1     1     GPT-3.5             gpt35   \n",
       "1                2       0        E    1     0     GPT-3.5             gpt35   \n",
       "2                3       1        P    0     0     GPT-3.5             gpt35   \n",
       "3                4       0        E    1     0     GPT-3.5             gpt35   \n",
       "4                5       0        L    0     1     GPT-3.5             gpt35   \n",
       "\n",
       "  population_display  \n",
       "0               Base  \n",
       "1               Base  \n",
       "2               Base  \n",
       "3               Base  \n",
       "4               Base  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load EPQR-A questionnaire experiment data\n",
    "with conn.connect() as connection:\n",
    "    epqra_data = data_access.load_questionnaire_experiments(\n",
    "        connection, \n",
    "        schema=SCHEMA,\n",
    "        questionnaires=[\"epqra\"]\n",
    "    )\n",
    "\n",
    "print(f\"Total EPQR-A records: {len(epqra_data)}\")\n",
    "print(f\"Experiment groups: {sorted(epqra_data['experiments_group_id'].unique())}\")\n",
    "print(f\"Models: {sorted(epqra_data['model_clean'].unique())}\")\n",
    "print(f\"Populations: {sorted(epqra_data['population_display'].unique())}\")\n",
    "print(f\"Categories: {sorted(epqra_data['category'].unique())}\")\n",
    "\n",
    "epqra_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "db67dfc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading reference questionnaire data...\n",
      "\n",
      "Loaded 19824 reference questionnaire records\n",
      "Unique personalities: 826\n",
      "Questions per personality: 24\n",
      "Categories: ['E', 'L', 'N', 'P']\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "personality_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "question_number",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "question",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "category",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "key",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "answer",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "ref_eval",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "aed2d2c8-824e-4784-a356-41c6fc90a411",
       "rows": [
        [
         "0",
         "1",
         "1",
         "1",
         "Does your mood often go up and down?",
         "N",
         "True",
         "True",
         "1"
        ],
        [
         "1",
         "2",
         "1",
         "2",
         "Are you a talkative person?",
         "E",
         "True",
         "False",
         "0"
        ],
        [
         "2",
         "3",
         "1",
         "3",
         "Would being in debt worry you?",
         "P",
         "False",
         "True",
         "0"
        ],
        [
         "3",
         "4",
         "1",
         "4",
         "Are you rather lively?",
         "E",
         "True",
         "False",
         "0"
        ],
        [
         "4",
         "5",
         "1",
         "5",
         "Were you ever greedy by helping yourself to more than your share of anything?",
         "L",
         "False",
         "False",
         "1"
        ]
       ],
       "shape": {
        "columns": 8,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>personality_id</th>\n",
       "      <th>question_number</th>\n",
       "      <th>question</th>\n",
       "      <th>category</th>\n",
       "      <th>key</th>\n",
       "      <th>answer</th>\n",
       "      <th>ref_eval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Does your mood often go up and down?</td>\n",
       "      <td>N</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Are you a talkative person?</td>\n",
       "      <td>E</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Would being in debt worry you?</td>\n",
       "      <td>P</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>Are you rather lively?</td>\n",
       "      <td>E</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>Were you ever greedy by helping yourself to mo...</td>\n",
       "      <td>L</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  personality_id  question_number  \\\n",
       "0   1               1                1   \n",
       "1   2               1                2   \n",
       "2   3               1                3   \n",
       "3   4               1                4   \n",
       "4   5               1                5   \n",
       "\n",
       "                                            question category    key  answer  \\\n",
       "0               Does your mood often go up and down?        N   True    True   \n",
       "1                        Are you a talkative person?        E   True   False   \n",
       "2                     Would being in debt worry you?        P  False    True   \n",
       "3                             Are you rather lively?        E   True   False   \n",
       "4  Were you ever greedy by helping yourself to mo...        L  False   False   \n",
       "\n",
       "   ref_eval  \n",
       "0         1  \n",
       "1         0  \n",
       "2         0  \n",
       "3         0  \n",
       "4         1  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load reference questionnaire data (input personality profiles)\n",
    "print(\"Loading reference questionnaire data...\")\n",
    "reference_data = data_access.load_reference_questionnaires(conn, schema=SCHEMA)\n",
    "\n",
    "print(f\"\\nLoaded {len(reference_data)} reference questionnaire records\")\n",
    "print(f\"Unique personalities: {reference_data['personality_id'].nunique()}\")\n",
    "print(f\"Questions per personality: {len(reference_data) // reference_data['personality_id'].nunique()}\")\n",
    "print(f\"Categories: {sorted(reference_data['category'].unique())}\")\n",
    "\n",
    "reference_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913ce950",
   "metadata": {},
   "source": [
    "## Merge Experiment and Reference Data\n",
    "\n",
    "Match LLM-generated answers with their corresponding reference (input) answers by `personality_id` and `question_number`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "44824400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged 297360 records\n",
      "\n",
      "Columns: ['experiments_group_id', 'model_clean', 'population_display', 'personality_id', 'experiment_id', 'question_number', 'answer_exp', 'category', 'key_exp', 'answer_ref', 'key_ref']\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "experiments_group_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "model_clean",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "population_display",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "personality_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "experiment_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "question_number",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "answer_exp",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "category",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "key_exp",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "answer_ref",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "key_ref",
         "rawType": "bool",
         "type": "boolean"
        }
       ],
       "ref": "a3371716-c937-4c03-a799-708f20ffbbcb",
       "rows": [
        [
         "0",
         "307",
         "GPT-3.5",
         "Base",
         "1",
         "96033",
         "1",
         "1",
         "N",
         "1",
         "True",
         "True"
        ],
        [
         "1",
         "307",
         "GPT-3.5",
         "Base",
         "1",
         "96033",
         "2",
         "0",
         "E",
         "1",
         "False",
         "True"
        ],
        [
         "2",
         "307",
         "GPT-3.5",
         "Base",
         "1",
         "96033",
         "3",
         "1",
         "P",
         "0",
         "True",
         "False"
        ],
        [
         "3",
         "307",
         "GPT-3.5",
         "Base",
         "1",
         "96033",
         "4",
         "0",
         "E",
         "1",
         "False",
         "True"
        ],
        [
         "4",
         "307",
         "GPT-3.5",
         "Base",
         "1",
         "96033",
         "5",
         "0",
         "L",
         "0",
         "False",
         "False"
        ]
       ],
       "shape": {
        "columns": 11,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiments_group_id</th>\n",
       "      <th>model_clean</th>\n",
       "      <th>population_display</th>\n",
       "      <th>personality_id</th>\n",
       "      <th>experiment_id</th>\n",
       "      <th>question_number</th>\n",
       "      <th>answer_exp</th>\n",
       "      <th>category</th>\n",
       "      <th>key_exp</th>\n",
       "      <th>answer_ref</th>\n",
       "      <th>key_ref</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>307</td>\n",
       "      <td>GPT-3.5</td>\n",
       "      <td>Base</td>\n",
       "      <td>1</td>\n",
       "      <td>96033</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>307</td>\n",
       "      <td>GPT-3.5</td>\n",
       "      <td>Base</td>\n",
       "      <td>1</td>\n",
       "      <td>96033</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>E</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>307</td>\n",
       "      <td>GPT-3.5</td>\n",
       "      <td>Base</td>\n",
       "      <td>1</td>\n",
       "      <td>96033</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>P</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>307</td>\n",
       "      <td>GPT-3.5</td>\n",
       "      <td>Base</td>\n",
       "      <td>1</td>\n",
       "      <td>96033</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>E</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>307</td>\n",
       "      <td>GPT-3.5</td>\n",
       "      <td>Base</td>\n",
       "      <td>1</td>\n",
       "      <td>96033</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>L</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   experiments_group_id model_clean population_display  personality_id  \\\n",
       "0                   307     GPT-3.5               Base               1   \n",
       "1                   307     GPT-3.5               Base               1   \n",
       "2                   307     GPT-3.5               Base               1   \n",
       "3                   307     GPT-3.5               Base               1   \n",
       "4                   307     GPT-3.5               Base               1   \n",
       "\n",
       "   experiment_id  question_number  answer_exp category  key_exp  answer_ref  \\\n",
       "0          96033                1           1        N        1        True   \n",
       "1          96033                2           0        E        1       False   \n",
       "2          96033                3           1        P        0        True   \n",
       "3          96033                4           0        E        1       False   \n",
       "4          96033                5           0        L        0       False   \n",
       "\n",
       "   key_ref  \n",
       "0     True  \n",
       "1     True  \n",
       "2    False  \n",
       "3     True  \n",
       "4    False  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge experiment data with reference data\n",
    "# Select relevant columns from epqra_data\n",
    "exp_cols = [\n",
    "    'experiments_group_id', 'model_clean', 'population_display', \n",
    "    'personality_id', 'experiment_id', 'question_number', \n",
    "    'answer', 'category', 'key'\n",
    "]\n",
    "\n",
    "# Select relevant columns from reference_data\n",
    "ref_cols = [\n",
    "    'personality_id', 'question_number', 'answer', 'key'\n",
    "]\n",
    "\n",
    "# Create merged dataframe\n",
    "accuracy_df = pd.merge(\n",
    "    epqra_data[exp_cols],\n",
    "    reference_data[ref_cols],\n",
    "    on=['personality_id', 'question_number'],\n",
    "    how='left',\n",
    "    suffixes=('_exp', '_ref')\n",
    ")\n",
    "\n",
    "print(f\"Merged {len(accuracy_df)} records\")\n",
    "print(f\"\\nColumns: {accuracy_df.columns.tolist()}\")\n",
    "accuracy_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34fdfb1",
   "metadata": {},
   "source": [
    "## Calculate Binary Classification Metrics\n",
    "\n",
    "For each experiment-question pair, compute:\n",
    "- Whether the answers match (`equal`)\n",
    "- True Positives, True Negatives, False Positives, False Negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dc4becd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary classification metrics calculated\n",
      "\n",
      "Sample confusion matrix components:\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "model_clean",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "population_display",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "category",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "question_number",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "equal",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "tp",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "tn",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "pred_pos",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "act_pos",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "24133ab2-fb03-4eb0-a4e7-b0e97562d77b",
       "rows": [
        [
         "0",
         "GPT-3.5",
         "Base",
         "N",
         "1",
         "True",
         "1",
         "0",
         "1",
         "1"
        ],
        [
         "1",
         "GPT-3.5",
         "Base",
         "E",
         "2",
         "True",
         "0",
         "1",
         "0",
         "0"
        ],
        [
         "2",
         "GPT-3.5",
         "Base",
         "P",
         "3",
         "True",
         "1",
         "0",
         "1",
         "1"
        ],
        [
         "3",
         "GPT-3.5",
         "Base",
         "E",
         "4",
         "True",
         "0",
         "1",
         "0",
         "0"
        ],
        [
         "4",
         "GPT-3.5",
         "Base",
         "L",
         "5",
         "True",
         "0",
         "1",
         "0",
         "0"
        ],
        [
         "5",
         "GPT-3.5",
         "Base",
         "P",
         "6",
         "True",
         "0",
         "1",
         "0",
         "0"
        ],
        [
         "6",
         "GPT-3.5",
         "Base",
         "L",
         "7",
         "True",
         "0",
         "1",
         "0",
         "0"
        ],
        [
         "7",
         "GPT-3.5",
         "Base",
         "P",
         "8",
         "True",
         "0",
         "1",
         "0",
         "0"
        ],
        [
         "8",
         "GPT-3.5",
         "Base",
         "N",
         "9",
         "True",
         "1",
         "0",
         "1",
         "1"
        ],
        [
         "9",
         "GPT-3.5",
         "Base",
         "L",
         "10",
         "True",
         "0",
         "1",
         "0",
         "0"
        ]
       ],
       "shape": {
        "columns": 9,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_clean</th>\n",
       "      <th>population_display</th>\n",
       "      <th>category</th>\n",
       "      <th>question_number</th>\n",
       "      <th>equal</th>\n",
       "      <th>tp</th>\n",
       "      <th>tn</th>\n",
       "      <th>pred_pos</th>\n",
       "      <th>act_pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GPT-3.5</td>\n",
       "      <td>Base</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GPT-3.5</td>\n",
       "      <td>Base</td>\n",
       "      <td>E</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GPT-3.5</td>\n",
       "      <td>Base</td>\n",
       "      <td>P</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GPT-3.5</td>\n",
       "      <td>Base</td>\n",
       "      <td>E</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GPT-3.5</td>\n",
       "      <td>Base</td>\n",
       "      <td>L</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GPT-3.5</td>\n",
       "      <td>Base</td>\n",
       "      <td>P</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GPT-3.5</td>\n",
       "      <td>Base</td>\n",
       "      <td>L</td>\n",
       "      <td>7</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GPT-3.5</td>\n",
       "      <td>Base</td>\n",
       "      <td>P</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GPT-3.5</td>\n",
       "      <td>Base</td>\n",
       "      <td>N</td>\n",
       "      <td>9</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GPT-3.5</td>\n",
       "      <td>Base</td>\n",
       "      <td>L</td>\n",
       "      <td>10</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model_clean population_display category  question_number  equal  tp  tn  \\\n",
       "0     GPT-3.5               Base        N                1   True   1   0   \n",
       "1     GPT-3.5               Base        E                2   True   0   1   \n",
       "2     GPT-3.5               Base        P                3   True   1   0   \n",
       "3     GPT-3.5               Base        E                4   True   0   1   \n",
       "4     GPT-3.5               Base        L                5   True   0   1   \n",
       "5     GPT-3.5               Base        P                6   True   0   1   \n",
       "6     GPT-3.5               Base        L                7   True   0   1   \n",
       "7     GPT-3.5               Base        P                8   True   0   1   \n",
       "8     GPT-3.5               Base        N                9   True   1   0   \n",
       "9     GPT-3.5               Base        L               10   True   0   1   \n",
       "\n",
       "   pred_pos  act_pos  \n",
       "0         1        1  \n",
       "1         0        0  \n",
       "2         1        1  \n",
       "3         0        0  \n",
       "4         0        0  \n",
       "5         0        0  \n",
       "6         0        0  \n",
       "7         0        0  \n",
       "8         1        1  \n",
       "9         0        0  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate equality (simple accuracy)\n",
    "accuracy_df['equal'] = accuracy_df['answer_exp'] == accuracy_df['answer_ref']\n",
    "\n",
    "# Compute true positives, predicted positives, and actual positives\n",
    "accuracy_df['tp'] = ((accuracy_df['answer_exp'] == True) & (accuracy_df['answer_ref'] == True)).astype(int)\n",
    "accuracy_df['pred_pos'] = (accuracy_df['answer_exp'] == True).astype(int)\n",
    "accuracy_df['act_pos'] = (accuracy_df['answer_ref'] == True).astype(int)\n",
    "\n",
    "# Compute true negatives, predicted negatives, and actual negatives\n",
    "accuracy_df['tn'] = ((accuracy_df['answer_exp'] == False) & (accuracy_df['answer_ref'] == False)).astype(int)\n",
    "accuracy_df['pred_neg'] = (accuracy_df['answer_exp'] == False).astype(int)\n",
    "accuracy_df['act_neg'] = (accuracy_df['answer_ref'] == False).astype(int)\n",
    "\n",
    "print(\"Binary classification metrics calculated\")\n",
    "print(f\"\\nSample confusion matrix components:\")\n",
    "accuracy_df[[\n",
    "    'model_clean', 'population_display', 'category', 'question_number',\n",
    "    'equal', 'tp', 'tn', 'pred_pos', 'act_pos'\n",
    "]].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144d6fad",
   "metadata": {},
   "source": [
    "## Helper Functions for Metric Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8a0ae863",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions are now available from the table_accuracy module# - table_accuracy.calculate_accuracy_metrics()# - table_accuracy.compute_error_metrics()# - table_accuracy.format_metrics_table()print(\"✅ Using table_accuracy module functions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5296c0",
   "metadata": {},
   "source": [
    "## Table A6: Base Population Accuracy Metrics\n",
    "\n",
    "Average accuracy and error metrics by EPQR-A scale for **Base population** compared to input reference.\n",
    "\n",
    "This table shows how well LLMs reproduce the reference personality profiles when generating standard (non-manipulated) personas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "15954223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base population records: 99120\n",
      "Models in Base population: ['Claude-3.5-s', 'GPT-3.5', 'GPT-4o', 'Llama3.1-70B', 'Llama3.2-3B']\n",
      "Categories: ['E', 'L', 'N', 'P']\n"
     ]
    }
   ],
   "source": [
    "# Filter to Base population only\n",
    "base_data = accuracy_df[accuracy_df['population_display'] == 'Base'].copy()\n",
    "\n",
    "print(f\"Base population records: {len(base_data)}\")\n",
    "print(f\"Models in Base population: {sorted(base_data['model_clean'].unique())}\")\n",
    "print(f\"Categories: {sorted(base_data['category'].unique())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7782fbd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate accuracy metrics for Base populationbase_metrics = table_accuracy.calculate_accuracy_metrics(    base_data,     group_by=['model_clean', 'category'])# Calculate error metrics (MAE, RMSE)base_errors = table_accuracy.compute_error_metrics(    base_data,    group_by_base=['model_clean'])# Merge metrics with errorsTABLE_A6 = pd.merge(    base_metrics,    base_errors,    on=['model_clean', 'category'],    how='left')# Format for displayTABLE_A6 = table_accuracy.format_metrics_table(    TABLE_A6,    model_col='model_clean',    population_col=None)# Select key columns for displaydisplay_cols = ['model_clean', 'category', 'accuracy', 'precision', 'recall', 'specificity', 'mae', 'rmse']TABLE_A6_display = TABLE_A6[display_cols]print(\"\\n\" + \"=\"*80)print(\"TABLE A6: Accuracy and Error Metrics for Base Population vs Reference\")print(\"=\"*80)print(\"\\nMetrics by Model and EPQR-A Category:\")display(TABLE_A6_display)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f5121e",
   "metadata": {},
   "source": [
    "## Table A7: MaxN/MaxP Population Accuracy Metrics\n",
    "\n",
    "Average accuracy and error metrics by EPQR-A scale for **MaxN and MaxP populations** compared to input reference.\n",
    "\n",
    "This table shows how well LLMs reproduce the reference personality profiles when generating personas with manipulated traits (maximized Neuroticism or Psychoticism)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "eddbc5b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MaxN/MaxP population records: 198240\n",
      "Models: ['Claude-3.5-s', 'GPT-3.5', 'GPT-4o', 'Llama3.1-70B', 'Llama3.2-3B']\n",
      "Populations: ['MaxN', 'MaxP']\n",
      "Categories: ['E', 'L', 'N', 'P']\n"
     ]
    }
   ],
   "source": [
    "# Filter to MaxN and MaxP populations\n",
    "borderline_data = accuracy_df[\n",
    "    accuracy_df['population_display'].isin(['MaxN', 'MaxP'])\n",
    "].copy()\n",
    "\n",
    "print(f\"MaxN/MaxP population records: {len(borderline_data)}\")\n",
    "print(f\"Models: {sorted(borderline_data['model_clean'].unique())}\")\n",
    "print(f\"Populations: {sorted(borderline_data['population_display'].unique())}\")\n",
    "print(f\"Categories: {sorted(borderline_data['category'].unique())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c3122ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate accuracy metrics for MaxN/MaxP populationsborderline_metrics = table_accuracy.calculate_accuracy_metrics(    borderline_data,    group_by=['model_clean', 'population_display', 'category'])# Calculate error metrics (MAE, RMSE)borderline_errors = table_accuracy.compute_error_metrics(    borderline_data,    group_by_base=['model_clean', 'population_display'])# Merge metrics with errorsTABLE_A7 = pd.merge(    borderline_metrics,    borderline_errors,    on=['model_clean', 'population_display', 'category'],    how='left')# Format for displayTABLE_A7 = table_accuracy.format_metrics_table(    TABLE_A7,    model_col='model_clean',    population_col='population_display')# Select key columns for displaydisplay_cols = ['model_clean', 'population_display', 'category', 'accuracy', 'precision', 'recall', 'specificity', 'mae', 'rmse']TABLE_A7_display = TABLE_A7[display_cols]print(\"\\n\" + \"=\"*80)print(\"TABLE A7: Accuracy and Error Metrics for MaxN/MaxP Populations vs Reference\")print(\"=\"*80)print(\"\\nMetrics by Model, Population, and EPQR-A Category:\")display(TABLE_A7_display)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08564df",
   "metadata": {},
   "source": [
    "## Summary Statistics\n",
    "\n",
    "Compare average metrics across populations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1ccec1c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TABLE A6: Base Population Summary\n",
      "============================================================\n",
      "Total rows: 20\n",
      "Models: 5\n",
      "Categories: 4\n",
      "\n",
      "============================================================\n",
      "TABLE A7: MaxN/MaxP Populations Summary\n",
      "============================================================\n",
      "Total rows: 40\n",
      "Models: 5\n",
      "Populations: 2\n",
      "Categories: 4\n"
     ]
    }
   ],
   "source": [
    "# Note: Since values are formatted as strings using custom_format,\n",
    "# we display the tables directly without additional statistics\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TABLE A6: Base Population Summary\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total rows: {len(TABLE_A6_display)}\")\n",
    "print(f\"Models: {TABLE_A6_display['model_clean'].nunique()}\")\n",
    "print(f\"Categories: {TABLE_A6_display['category'].nunique()}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TABLE A7: MaxN/MaxP Populations Summary\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total rows: {len(TABLE_A7_display)}\")\n",
    "print(f\"Models: {TABLE_A7_display['model_clean'].nunique()}\")\n",
    "print(f\"Populations: {TABLE_A7_display['population_display'].nunique()}\")\n",
    "print(f\"Categories: {TABLE_A7_display['category'].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050e98cf",
   "metadata": {},
   "source": [
    "## Export Tables\n",
    "\n",
    "Save tables for inclusion in the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b599027f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Table A6 saved to: table_a6_base_accuracy.csv\n",
      "✅ Table A7 saved to: table_a7_borderline_accuracy.csv\n"
     ]
    }
   ],
   "source": [
    "# Save Table A6\n",
    "output_a6 = \"table_a6_base_accuracy.csv\"\n",
    "TABLE_A6_display.to_csv(output_a6, index=False)\n",
    "print(f\"✅ Table A6 saved to: {output_a6}\")\n",
    "\n",
    "# Save Table A7\n",
    "output_a7 = \"table_a7_borderline_accuracy.csv\"\n",
    "TABLE_A7_display.to_csv(output_a7, index=False)\n",
    "print(f\"✅ Table A7 saved to: {output_a7}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
